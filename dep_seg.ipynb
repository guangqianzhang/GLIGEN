{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T05:27:33.943545044Z",
     "start_time": "2023-07-01T05:27:33.777204294Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating in tst: 100%|██████████| 40/40 [00:00<00:00, 230.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'json' from '/home/cqjtu/anaconda3/envs/gligen/lib/python3.8/json/__init__.py'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "imgpath = '/home/cqjtu/Documents/dataset/gligen/test/img'\n",
    "jsonfile_name = '/home/cqjtu/Documents/dataset/gligen/test/test_caption.json'\n",
    "jsonfile_origin = '/home/cqjtu/Documents/dataset/gligen/nusenes_train_images_cation.json'\n",
    "data = dict()\n",
    "\n",
    "for home, dirs, files in os.walk(imgpath):\n",
    "    for filename in tqdm(files, desc='generating in tst'):\n",
    "        with open(jsonfile_origin, 'r') as fo:\n",
    "            json_data = json.load(fo)\n",
    "            data[filename] = json_data[filename]\n",
    "\n",
    "with open(jsonfile_name, 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T11:01:28.028134594Z",
     "start_time": "2023-07-01T11:01:28.025521625Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import random\n",
    "from trainer import Trainer\n",
    "from distributed import synchronize\n",
    "import os\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--DATA_ROOT\", type=str,  default=\"/home/cqjtu/Documents/dataset/gligen/test\", help=\"path to DATA\")\n",
    "parser.add_argument(\"--OUTPUT_ROOT\", type=str,  default=\"OUTPUT\", help=\"path to OUTPUT\")\n",
    "\n",
    "parser.add_argument(\"--name\", type=str,  default=\"test\", help=\"experiment will be stored in OUTPUT_ROOT/name\")\n",
    "parser.add_argument(\"--seed\", type=int,  default=123, help=\"used in sampler\")\n",
    "parser.add_argument(\"--local_rank\", type=int, default=0)\n",
    "parser.add_argument(\"--yaml_file\", type=str,  default=\"configs/depth_sem.yaml\", help=\"paths to base configs.\")\n",
    "\n",
    "\n",
    "parser.add_argument(\"--base_learning_rate\", type=float,  default=5e-5, help=\"\")\n",
    "parser.add_argument(\"--weight_decay\", type=float,  default=0.0, help=\"\")\n",
    "parser.add_argument(\"--warmup_steps\", type=int,  default=10000, help=\"\")\n",
    "parser.add_argument(\"--scheduler_type\", type=str,  default='constant', help=\"cosine or constant\")\n",
    "parser.add_argument(\"--batch_size\", type=int,  default=2, help=\"\")\n",
    "parser.add_argument(\"--workers\", type=int,  default=1, help=\"\")\n",
    "parser.add_argument(\"--official_ckpt_name\", type=str,  default=\"sd-v1-4.ckpt\", help=\"SD ckpt name and it is expected in DATA_ROOT, thus DATA_ROOT/official_ckpt_name must exists\")\n",
    "parser.add_argument(\"--ckpt\", type=lambda x:x if type(x) == str and x.lower() != \"none\" else None,  default=None,\n",
    "    help=(\"If given, then it will start training from this ckpt\"\n",
    "          \"It has higher prioty than official_ckpt_name, but lower than the ckpt found in autoresuming (see trainer.py) \"\n",
    "          \"It must be given if inpaint_mode is true\")\n",
    ")\n",
    "\n",
    "parser.add_argument('--inpaint_mode', default=False, type=lambda x:x.lower() == \"true\", help=\"Train a GLIGEN model in inpaitning setting\")\n",
    "parser.add_argument('--randomize_fg_mask', default=False, type=lambda x:x.lower() == \"true\", help=\"Only used if inpaint_mode is true. If true, 0.5 chance that fg mask will not be a box but a random mask. See code for details\")\n",
    "parser.add_argument('--random_add_bg_mask', default=False, type=lambda x:x.lower() == \"true\", help=\"Only used if inpaint_mode is true. If true, 0.5 chance add arbitrary mask for the whole image. See code for details\")\n",
    "\n",
    "parser.add_argument('--enable_ema', default=False, type=lambda x:x.lower() == \"true\")\n",
    "parser.add_argument(\"--ema_rate\", type=float,  default=0.9999, help=\"\")\n",
    "parser.add_argument(\"--total_iters\", type=int,  default=500000, help=\"\")\n",
    "parser.add_argument(\"--save_every_iters\", type=int,  default=5000, help=\"\")\n",
    "parser.add_argument(\"--disable_inference_in_training\", type=lambda x:x.lower() == \"true\",  default=False, help=\"Do not do inference, thus it is faster to run first a few iters. It may be useful for debugging \")\n",
    "\n",
    "\n",
    "args = parser.parse_args()\n",
    "assert args.scheduler_type in ['cosine', 'constant']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_gpu = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "args.distributed = n_gpu > 1\n",
    "\n",
    "if args.distributed:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
    "    synchronize()\n",
    "\n",
    "\n",
    "\n",
    "config = OmegaConf.load(args.yaml_file)\n",
    "config.update( vars(args) )\n",
    "config.total_batch_size = config.batch_size * n_gpu\n",
    "if args.inpaint_mode:\n",
    "    config.model.params.inpaint_mode = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T11:02:31.818541694Z",
     "start_time": "2023-07-01T11:02:31.777049178Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset.concat_dataset import ConCatDataset\n",
    "dataset_train=ConCatDataset(config.train_dataset_names,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T11:02:39.985269835Z",
     "start_time": "2023-07-01T11:02:39.962757971Z"
    }
   },
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
